# synix

> A build system for agent memory

## What it does

Synix transforms raw conversations into searchable, hierarchical memory with full provenance tracking. It processes chat logs through configurable DAGs of LLM-backed transforms and aggregates, producing memory artifacts at multiple levels of abstraction. Think `make` or `dbt`, but for AI agent memory — change a config, only affected layers rebuild.

## Key concepts

- **Artifact** — immutable, versioned build output (transcript, episode, rollup, core memory). Content-addressed via SHA256.
- **Layer** — named level in the memory hierarchy. Layers form a DAG (transcripts → episodes → rollups → core).
- **Pipeline** — declared in Python. Defines layers, transforms, grouping strategies, and projections.
- **Projection** — materializes artifacts into usable outputs (search index via SQLite FTS5, context doc as markdown).
- **Provenance** — every artifact traces back to its inputs. Always included in search results.
- **Cache/Rebuild** — hash comparison: if inputs or prompt changed, rebuild. Otherwise skip.

## Installation and quick start

```bash
# Install
pip install synix

# Initialize project with example data
synix init my-memory --from ~/exports/conversations.json

# Build the pipeline
synix build

# Search with provenance
synix search "that rust conversation" --trace
```

## CLI commands

```bash
synix init <name>           # Create new project
synix build                 # Run pipeline, rebuild only what changed
synix plan                  # Show what would build (dry-run)
synix search <query>        # Full-text + semantic search across layers
synix search <query> --layers episodes,core  # Search specific layers
synix lineage <artifact-id> # Show full provenance chain
synix status               # Build summary and cache stats
synix validate             # Run validators against artifacts
synix verify               # Check build integrity
```

## Architecture overview

```
src/synix/
├── cli.py              # Click CLI commands
├── pipeline/
│   ├── config.py       # Parse pipeline Python module
│   ├── dag.py          # DAG resolution, build order, rebuild detection
│   └── runner.py       # Execute pipeline, walk DAG, cache artifacts
├── artifacts/
│   ├── store.py        # Artifact storage (filesystem-backed)
│   └── provenance.py   # Provenance tracking and lineage queries
├── transforms/
│   ├── base.py         # Transform interface
│   ├── parse.py        # Source parsers (ChatGPT/Claude JSON → artifacts)
│   ├── summarize.py    # LLM transforms (episode, rollup, core synthesis)
│   └── prompts/        # Prompt templates as text files
├── projections/
│   ├── search_index.py # SQLite FTS5 materialization and queries
│   └── flat_file.py    # Render artifacts as context documents
└── sources/
    ├── chatgpt.py      # ChatGPT export parser
    └── claude.py       # Claude export parser
```

## Pipeline definition

Pipelines are defined in Python, not config files:

```python
from synix import Pipeline, Layer, Projection

pipeline = Pipeline("personal-memory")
pipeline.source_dir = "./exports"
pipeline.llm_config = {"model": "claude-sonnet-4-20250514"}

# Layers form a dependency DAG
pipeline.add_layer(Layer(name="transcripts", level=0, transform="parse"))
pipeline.add_layer(Layer(name="episodes", level=1, depends_on=["transcripts"], 
                         transform="episode_summary", grouping="by_conversation"))
pipeline.add_layer(Layer(name="monthly", level=2, depends_on=["episodes"],
                         transform="monthly_rollup", grouping="by_month"))
pipeline.add_layer(Layer(name="core", level=3, depends_on=["monthly"],
                         transform="core_synthesis", grouping="single"))

# Projections materialize artifacts for use
pipeline.add_projection(Projection(name="memory-index", projection_type="search_index",
                                   sources=[{"layer": "episodes"}, {"layer": "monthly"}]))
```

## Important constraints

- **SQLite + filesystem only** — no external databases, no Docker, no web server
- **Python 3.11+** required
- **Environment variables** — `ANTHROPIC_API_KEY` or `OPENAI_API_KEY` needed for LLM calls
- **UV-native** — uses `uv` for dependency management (`uv sync`, `uv run synix`)
- **Content-addressed caching** — artifacts are immutable, rebuilds are deterministic
- **DAG execution only** — no branching or parallel pipeline variants (yet)